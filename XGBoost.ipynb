{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optuna\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, \\\n",
    "                            precision_recall_curve, roc_curve, accuracy_score\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import xgboost as xgb\n",
    "from optuna import create_study, logging\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.integration import XGBoostPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "\n",
    "Xtr_loadpath = 'Xtr.csv'\n",
    "Xts_loadpath = 'Xts.csv'\n",
    "ytr_loadpath = 'ytr.csv'\n",
    "#Xtr = np.loadtxt(Xtr_loadpath, delimiter=\",\", usecols = (2,3,5,6,7))\n",
    "#Xts = np.loadtxt(Xts_loadpath, delimiter=\",\", usecols = (2,3,5,6,7))\n",
    "Xtr = np.loadtxt(Xtr_loadpath, delimiter=\",\")\n",
    "Xts = np.loadtxt(Xts_loadpath, delimiter=\",\")\n",
    "ytr = np.loadtxt(ytr_loadpath, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the training data\n",
    "Xtr_standardized = Xtr # revise this line as needed\n",
    "Xts_standardized = Xts # revise this line as needed\n",
    "ytr_standardized = ytr # revise this line as needed\n",
    "\n",
    "# save the standardized training data\n",
    "Xtr_savepath = 'Xtr_xgboost.csv'\n",
    "Xts_savepath = 'Xts_xgboost.csv'\n",
    "ytr_savepath = 'ytr_xgboost.csv'\n",
    "yts_hat_savepath = 'yts_hat_xgboost.csv'\n",
    "\n",
    "np.savetxt(Xtr_savepath, Xtr_standardized, delimiter=\",\")\n",
    "np.savetxt(Xts_savepath, Xts_standardized, delimiter=\",\")\n",
    "np.savetxt(ytr_savepath, ytr_standardized, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y, group, score, params=dict()):\n",
    "    dtrain = xgb.DMatrix(X, label=y)\n",
    "    class_weight = (y.shape[0] - np.sum(y)) / np.sum(y)\n",
    "    \n",
    "    ## Initial Learning Parameters\n",
    "    params['learning_rate'] = 0.1\n",
    "    params['num_boost_round'] = 1000\n",
    "\n",
    "    if group == '1':\n",
    "        params['max_depth'] = trial.suggest_int('max_depth', 2, 10)\n",
    "        params['min_child_weight'] = trial.suggest_loguniform('min_child_weight',\n",
    "                                                              1e-10, 1e10)\n",
    "    \n",
    "    if group == '2':\n",
    "        params['subsample'] = trial.suggest_uniform('subsample', 0, 1)\n",
    "        params['colsample_bytree'] = trial.suggest_uniform('colsample_bytree', 0, 1)\n",
    "    \n",
    "    if group == '3':\n",
    "        params['learning_rate'] = trial.suggest_uniform('learning_rate', 0, 0.1)\n",
    "        params['num_boost_round'] = trial.suggest_int('num_boost_round', 100, 1000)\n",
    "\n",
    "    pruning_callback = XGBoostPruningCallback(trial, \"test-\" + score.__name__)\n",
    "    cv_scores = xgb.cv(params, dtrain, nfold=5,\n",
    "                       stratified=True,\n",
    "                       feval=score,\n",
    "                       early_stopping_rounds=10,\n",
    "                       callbacks=[pruning_callback],\n",
    "                       seed=0)\n",
    "\n",
    "    return cv_scores['test-' + score.__name__ + '-mean'].values[-1]\n",
    "\n",
    "\n",
    "def execute_optimization(study_name, group, score, trials,\n",
    "                         params=dict(), direction='maximize'):\n",
    "    logging.set_verbosity(logging.ERROR)\n",
    "    \n",
    "    ## We use pruner to skip trials that are NOT fruitful\n",
    "    pruner = MedianPruner(n_warmup_steps=5)\n",
    "    \n",
    "    study = create_study(direction=direction,\n",
    "                         study_name=study_name,\n",
    "                         storage='sqlite:///optuna.db',\n",
    "                         load_if_exists=True,\n",
    "                         pruner=pruner)\n",
    "\n",
    "    study.optimize(lambda trial: objective(trial, x_train, y_train,\n",
    "                                           group, score, params),\n",
    "                   n_trials=trials,\n",
    "                   n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    print(\"STUDY NAME: \", study_name)\n",
    "    print('------------------------------------------------')\n",
    "    print(\"EVALUATION METRIC: \", score.__name__)\n",
    "    print('------------------------------------------------')\n",
    "    print(\"BEST CV SCORE\", study.best_value)\n",
    "    print('------------------------------------------------')\n",
    "    print(f\"OPTIMAL GROUP - {group} PARAMS: \", study.best_params)\n",
    "    print('------------------------------------------------')\n",
    "    print(\"BEST TRIAL\", study.best_trial)\n",
    "    print('------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_func = metrics.f1_score\n",
    "def score_function(y_pred, dtrain):\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    y_true = (dtrain.get_label() > 0.5).astype(int)\n",
    "    return score_func.__name__, score_func(y_true, y_pred)\n",
    "\n",
    "score_function.__name__ = score_func.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_optimization(trials=10):\n",
    "    final_params = dict()\n",
    "    for g in ['1', '2', '3']:\n",
    "        print(f\"=========================== Optimizing Group - {g} ============================\")\n",
    "        update_params = execute_optimization('xgboost', g, score_function, trials,\n",
    "                                             params=final_params, direction='maximize')\n",
    "        final_params.update(update_params)\n",
    "        print(f\"PARAMS after optimizing GROUP - {g}: \", final_params)\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    print(\"=========================== FINAL OPTIMAL PARAMETERS ============================\")\n",
    "    print(final_params)\n",
    "    \n",
    "    return final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = stepwise_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,ytrain,ytest = train_test_split(Xtr_standardized,ytr_standardized,test_size = 0.2,random_state= 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4.809999999999999692e-02</th>\n",
       "      <th>1.344749999999999943e+02</th>\n",
       "      <th>-2.328261189763562911e+01</th>\n",
       "      <th>8.628743749848529987e+00</th>\n",
       "      <th>3.684999999999999942e-01</th>\n",
       "      <th>1.667416484629477935e+01</th>\n",
       "      <th>-3.083019540169018580e+00</th>\n",
       "      <th>7.836462158890424234e+01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0939</td>\n",
       "      <td>67.2404</td>\n",
       "      <td>-34.186612</td>\n",
       "      <td>23.601344</td>\n",
       "      <td>0.6114</td>\n",
       "      <td>24.044165</td>\n",
       "      <td>-3.44682</td>\n",
       "      <td>6.277822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1450</td>\n",
       "      <td>173.2330</td>\n",
       "      <td>-42.646412</td>\n",
       "      <td>-21.425756</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>17.904165</td>\n",
       "      <td>-3.20612</td>\n",
       "      <td>3.391522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3157</td>\n",
       "      <td>66.8450</td>\n",
       "      <td>-96.218312</td>\n",
       "      <td>97.042544</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>27.973365</td>\n",
       "      <td>-3.65052</td>\n",
       "      <td>6.303522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1889</td>\n",
       "      <td>43.7205</td>\n",
       "      <td>-18.457012</td>\n",
       "      <td>9.089744</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>12.813565</td>\n",
       "      <td>-3.04932</td>\n",
       "      <td>62.272022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1277</td>\n",
       "      <td>170.9520</td>\n",
       "      <td>-28.211612</td>\n",
       "      <td>25.315844</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>19.756565</td>\n",
       "      <td>-3.11322</td>\n",
       "      <td>34.997722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4.809999999999999692e-02  1.344749999999999943e+02  \\\n",
       "0                    0.0939                   67.2404   \n",
       "1                    0.1450                  173.2330   \n",
       "2                    0.3157                   66.8450   \n",
       "3                    0.1889                   43.7205   \n",
       "4                    0.1277                  170.9520   \n",
       "\n",
       "   -2.328261189763562911e+01  8.628743749848529987e+00  \\\n",
       "0                 -34.186612                 23.601344   \n",
       "1                 -42.646412                -21.425756   \n",
       "2                 -96.218312                 97.042544   \n",
       "3                 -18.457012                  9.089744   \n",
       "4                 -28.211612                 25.315844   \n",
       "\n",
       "   3.684999999999999942e-01  1.667416484629477935e+01  \\\n",
       "0                    0.6114                 24.044165   \n",
       "1                    0.1280                 17.904165   \n",
       "2                    0.1004                 27.973365   \n",
       "3                    0.1966                 12.813565   \n",
       "4                    0.0892                 19.756565   \n",
       "\n",
       "   -3.083019540169018580e+00  7.836462158890424234e+01  \n",
       "0                   -3.44682                  6.277822  \n",
       "1                   -3.20612                  3.391522  \n",
       "2                   -3.65052                  6.303522  \n",
       "3                   -3.04932                 62.272022  \n",
       "4                   -3.11322                 34.997722  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# fit scaler on your training data\n",
    "norm = MinMaxScaler().fit(X_train)\n",
    "# transform your training data\n",
    "X_train_norm = norm.transform(X_train)\n",
    "# transform testing database\n",
    "X_test_norm = norm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26209012, 0.11002099, 0.15140432, 0.15012771, 0.32635695],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model=xgboost.XGBClassifier(n_estimators=100)\n",
    "model.fit(Xtr_standardized, ytr_standardized)\n",
    "model.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50,100, 200,500, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 7,8,12]\n",
    "booster = ['gbtree', 'gblinear','dart']\n",
    "base_score = [0.25, 0.5, 0.75, 1]\n",
    "learning_rate = [0.05, 0.1, 0.15, 0.20,0.25,0.30]\n",
    "gamma = [ 0.0, 0.1, 0.2 , 0.3, 0.4 ]\n",
    "min_child_weight = [1, 2, 3, 4,5]\n",
    "colsample_bytree = [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "colsample_bylevel = np.arange(0.5, 1.0, 0.1)\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'learning_rate' : learning_rate,\n",
    "    'min_child_weight' : min_child_weight,\n",
    "    'booster' : booster,\n",
    "    'base_score' : base_score,\n",
    "    'gamma': gamma,\n",
    "    'colsample_bytree': colsample_bytree,\n",
    "    'colsample_bylevel':colsample_bylevel\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:32:26] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001235bc615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012373bb37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001236cdbd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001236c188f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001236c1ba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x00000001235c290f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010e26fead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x000000030a898770 0x0 + 13061687152\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:32:26] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000121b23615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000121ca2b37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000121c34bd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000121c2888f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x0000000121c28ba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x0000000121b2990f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010c7d6ead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x000000030753e770 0x0 + 13007841136\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:32:27] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000121786615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000121905b37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000121897bd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012188b88f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x000000012188bba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012178c90f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010c439ead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x0000000306ee8770 0x0 + 13001197424\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:32:29] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000121b23615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000121ca2b37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000121c34bd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000121c2888f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x0000000121c28ba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x0000000121b2990f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010c7d6ead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x000000030753e770 0x0 + 13007841136\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:32:33] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000121b23615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000121ca2b37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000121c34bd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000121c2888f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x0000000121c28ba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x0000000121b2990f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010c7d6ead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x000000030753e770 0x0 + 13007841136\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:32:34] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001235bc615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012373bb37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001236cdbd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001236c188f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001236c1ba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x00000001235c290f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010e26fead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x000000030a898770 0x0 + 13061687152\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:32:39] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000121b23615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000121ca2b37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000121c34bd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000121c2888f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x0000000121c28ba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x0000000121b2990f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010c7d6ead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x000000030753e770 0x0 + 13007841136\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:32:39] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000121786615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000121905b37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000121897bd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012188b88f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x000000012188bba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012178c90f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010c439ead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x0000000306ee8770 0x0 + 13001197424\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:32:42] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000011f4ae615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000011f62db37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000011f5bfbd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000011f5b388f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x000000011f5b3ba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000011f4b490f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010a161ead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x00000003028e7770 0x0 + 12927793008\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:32:42] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001235bc615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012373bb37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001236cdbd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001236c188f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001236c1ba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x00000001235c290f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010e26fead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x000000030a898770 0x0 + 13061687152\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:32:50] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000121b23615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000121ca2b37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000121c34bd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000121c2888f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x0000000121c28ba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x0000000121b2990f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010c7d6ead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x000000030753e770 0x0 + 13007841136\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [22:58:50] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000121b23615 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000121ca2b37 xgboost::obj::LogisticRegression::ProbToMargin(float) + 199\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000121c34bd4 xgboost::LearnerConfiguration::ConfigureModelParamWithoutBaseScore() + 164\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000121c2888f xgboost::LearnerConfiguration::Configure() + 1279\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x0000000121c28ba9 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 105\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x0000000121b2990f XGBoosterUpdateOneIter + 143\n",
      "  [bt] (6) 7   libffi.7.dylib                      0x000000010c7d6ead ffi_call_unix64 + 85\n",
      "  [bt] (7) 8   ???                                 0x000000030753e770 0x0 + 13007841136\n",
      "\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.82308826 0.87626732 0.82326413 0.90928174 0.75808223 0.91437211\n",
      "        nan 0.82389399        nan        nan 0.90497723 0.82326282\n",
      "        nan 0.9164226  0.90771517 0.87115638        nan 0.82281484\n",
      " 0.88619868        nan 0.82435484 0.90651           nan        nan\n",
      " 0.8238941         nan 0.82289636 0.90671268 0.82326314        nan\n",
      " 0.90445928 0.82315464 0.86551443 0.89389649        nan 0.90735187\n",
      " 0.85768496 0.90340735 0.90803591 0.89997948 0.90334968 0.90328231\n",
      " 0.82305577 0.84859141 0.82478797 0.82289603 0.86896771 0.90682546\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/sowbaranika/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.8233508  0.94297756 0.82350087 0.99999999 0.75823264 0.99306943\n",
      "        nan 0.82404004        nan        nan 0.97887944 0.82349752\n",
      "        nan 0.9682906  0.92266028 0.96090015        nan 0.82297879\n",
      " 0.93760203        nan 0.82438179 0.99964947        nan        nan\n",
      " 0.8240375         nan 0.82314912 0.95263878 0.82350057        nan\n",
      " 0.99908263 0.82332146 0.9789526  0.9097285         nan 0.92103853\n",
      " 0.989692   0.99988423 0.99996971 0.99999977 0.99918739 0.92116145\n",
      " 0.82326084 0.99934441 0.82482837 0.82314738 0.97492649 1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.25, booster=&#x27;dart&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.7, colsample_bynode=1, colsample_bytree=0.7,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.2, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=5, max_leaves=0, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.25, booster=&#x27;dart&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.7, colsample_bynode=1, colsample_bytree=0.7,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.2, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=5, max_leaves=0, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.25, booster='dart', callbacks=None,\n",
       "              colsample_bylevel=0.7, colsample_bynode=1, colsample_bytree=0.7,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.2, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=5, max_leaves=0, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:32:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=7, min_child_weight=2, n_estimators=200;, score=(train=0.822, test=0.828) total time=   0.1s\n",
      "[22:32:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=7, min_child_weight=2, n_estimators=200;, score=(train=0.826, test=0.814) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=7, min_child_weight=5, n_estimators=100;, score=(train=0.942, test=0.883) total time=   0.3s\n",
      "[22:32:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=4, n_estimators=1100;, score=(train=0.823, test=0.820) total time=   0.7s\n",
      "[CV 2/5] END base_score=0.25, booster=dart, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=12, min_child_weight=2, n_estimators=200;, score=(train=1.000, test=0.909) total time=  11.6s\n",
      "[22:32:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=50;, score=(train=0.756, test=0.754) total time=   0.0s\n",
      "[22:32:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=50;, score=(train=0.756, test=0.767) total time=   0.0s\n",
      "[22:32:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=50;, score=(train=0.759, test=0.764) total time=   0.0s\n",
      "[22:32:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=50;, score=(train=0.759, test=0.752) total time=   0.0s\n",
      "[CV 2/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=50;, score=(train=0.992, test=0.916) total time=   0.3s\n",
      "[CV 4/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=50;, score=(train=0.994, test=0.920) total time=   0.3s\n",
      "[CV 2/5] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[22:32:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=5, n_estimators=500;, score=(train=0.822, test=0.834) total time=   0.3s\n",
      "[22:32:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=5, n_estimators=500;, score=(train=0.825, test=0.821) total time=   0.3s\n",
      "[CV 3/5] END base_score=0.75, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=2, n_estimators=50;, score=(train=0.979, test=0.905) total time=   1.0s\n",
      "[CV 4/5] END base_score=0.75, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=2, n_estimators=50;, score=(train=0.980, test=0.912) total time=   0.9s\n",
      "[CV 1/5] END base_score=1, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END base_score=1, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END base_score=0.25, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0.2, learning_rate=0.2, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=0.968, test=0.918) total time=   1.7s\n",
      "[CV 5/5] END base_score=0.25, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0.2, learning_rate=0.2, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=0.967, test=0.911) total time=   1.8s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=200;, score=(train=0.924, test=0.898) total time=   0.4s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=5, n_estimators=100;, score=(train=0.960, test=0.872) total time=   0.4s\n",
      "[CV 1/5] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=0.0, learning_rate=0.3, max_depth=7, min_child_weight=2, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=0.0, learning_rate=0.3, max_depth=7, min_child_weight=2, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=0.0, learning_rate=0.3, max_depth=7, min_child_weight=2, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=0.0, learning_rate=0.3, max_depth=7, min_child_weight=2, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=0.0, learning_rate=0.3, max_depth=7, min_child_weight=2, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[22:32:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.820, test=0.835) total time=   0.1s\n",
      "[22:32:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.822, test=0.827) total time=   0.1s\n",
      "[22:32:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.824, test=0.820) total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.2, learning_rate=0.3, max_depth=2, min_child_weight=2, n_estimators=500;, score=(train=0.937, test=0.886) total time=   0.7s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.2, learning_rate=0.3, max_depth=2, min_child_weight=2, n_estimators=500;, score=(train=0.936, test=0.897) total time=   0.7s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=0.0, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=1500;, score=(train=1.000, test=0.906) total time=   3.4s\n",
      "[CV 1/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END base_score=1, booster=dart, colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END base_score=1, booster=dart, colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=dart, colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=dart, colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=dart, colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[22:32:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7999999999999999, colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=2, n_estimators=500;, score=(train=0.823, test=0.829) total time=   0.3s\n",
      "[22:32:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7999999999999999, colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=2, n_estimators=500;, score=(train=0.825, test=0.821) total time=   0.3s\n",
      "[CV 1/5] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=2, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=2, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=2, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[22:32:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=0.822, test=0.828) total time=   0.7s\n",
      "[22:32:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=0.824, test=0.820) total time=   0.7s\n",
      "[CV 2/5] END base_score=0.75, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=1, n_estimators=50;, score=(train=0.953, test=0.910) total time=   0.7s\n",
      "[CV 5/5] END base_score=0.75, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=1, n_estimators=50;, score=(train=0.953, test=0.899) total time=   0.7s\n",
      "[22:32:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=2, n_estimators=1100;, score=(train=0.826, test=0.814) total time=   0.6s\n",
      "[CV 3/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=100;, score=(train=0.999, test=0.906) total time=   0.7s\n",
      "[CV 3/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=4, n_estimators=1500;, score=(train=0.978, test=0.868) total time=   6.2s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=2, min_child_weight=5, n_estimators=100;, score=(train=0.910, test=0.895) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=2, min_child_weight=5, n_estimators=100;, score=(train=0.908, test=0.901) total time=   0.2s\n",
      "[CV 1/5] END base_score=1, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END base_score=1, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=5, n_estimators=50;, score=(train=0.921, test=0.910) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=5, n_estimators=50;, score=(train=0.920, test=0.912) total time=   0.1s\n",
      "[CV 2/5] END base_score=0.75, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.3, gamma=0.2, learning_rate=0.2, max_depth=12, min_child_weight=5, n_estimators=500;, score=(train=0.989, test=0.858) total time= 1.2min\n",
      "[CV 1/5] END base_score=0.5, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.2, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.901) total time=  40.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.2, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.909) total time=  40.1s\n",
      "[CV 3/5] END base_score=0.25, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=1100;, score=(train=1.000, test=0.909) total time= 3.2min\n",
      "[CV 3/5] END base_score=0.5, booster=dart, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=5, n_estimators=1500;, score=(train=1.000, test=0.902) total time= 7.9min\n",
      "[CV 1/5] END base_score=0.25, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=1100;, score=(train=0.999, test=0.900) total time= 4.3min\n",
      "[CV 4/5] END base_score=0.25, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=1100;, score=(train=1.000, test=0.909) total time= 4.1min\n",
      "[CV 3/5] END base_score=0.5, booster=dart, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=1100;, score=(train=0.999, test=0.846) total time= 3.6min\n",
      "[CV 3/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.1, learning_rate=0.2, max_depth=12, min_child_weight=3, n_estimators=1500;, score=(train=1.000, test=0.909) total time=  11.1s\n",
      "[CV 1/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 2/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=8, min_child_weight=1, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=8, min_child_weight=1, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=8, min_child_weight=1, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=8, min_child_weight=1, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=8, min_child_weight=1, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:32:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=7, min_child_weight=2, n_estimators=200;, score=(train=0.821, test=0.833) total time=   0.1s\n",
      "[CV 1/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=7, min_child_weight=5, n_estimators=100;, score=(train=0.943, test=0.877) total time=   0.3s\n",
      "[22:32:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=4, n_estimators=1100;, score=(train=0.822, test=0.828) total time=   0.7s\n",
      "[CV 1/5] END base_score=0.25, booster=dart, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=12, min_child_weight=2, n_estimators=200;, score=(train=1.000, test=0.905) total time=  11.4s\n",
      "[CV 5/5] END base_score=0.25, booster=dart, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=12, min_child_weight=2, n_estimators=200;, score=(train=1.000, test=0.906) total time=  10.4s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=0.0, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=1500;, score=(train=1.000, test=0.910) total time=   3.4s\n",
      "[22:32:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7999999999999999, colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=2, n_estimators=500;, score=(train=0.826, test=0.815) total time=   0.3s\n",
      "[22:32:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=0.823, test=0.820) total time=   0.7s\n",
      "[CV 1/5] END base_score=0.75, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=1, n_estimators=50;, score=(train=0.952, test=0.906) total time=   0.7s\n",
      "[CV 4/5] END base_score=0.75, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=1, n_estimators=50;, score=(train=0.953, test=0.910) total time=   0.7s\n",
      "[22:32:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=2, n_estimators=1100;, score=(train=0.822, test=0.828) total time=   0.7s\n",
      "[CV 1/5] END base_score=1, booster=dart, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END base_score=1, booster=dart, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=dart, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=100;, score=(train=0.999, test=0.903) total time=   0.7s\n",
      "[CV 5/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=100;, score=(train=0.999, test=0.898) total time=   0.7s\n",
      "[CV 4/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=4, n_estimators=1500;, score=(train=0.979, test=0.876) total time=   6.3s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=5, n_estimators=50;, score=(train=0.919, test=0.910) total time=   0.1s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=5, n_estimators=50;, score=(train=0.923, test=0.899) total time=   0.1s\n",
      "[CV 3/5] END base_score=0.75, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.3, gamma=0.2, learning_rate=0.2, max_depth=12, min_child_weight=5, n_estimators=500;, score=(train=0.990, test=0.858) total time= 1.2min\n",
      "[CV 5/5] END base_score=0.75, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.3, gamma=0.2, learning_rate=0.2, max_depth=12, min_child_weight=5, n_estimators=500;, score=(train=0.990, test=0.847) total time= 1.1min\n",
      "[CV 2/5] END base_score=0.25, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=1100;, score=(train=1.000, test=0.905) total time= 3.2min\n",
      "[CV 1/5] END base_score=0.5, booster=dart, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=5, n_estimators=1500;, score=(train=1.000, test=0.897) total time= 7.9min\n",
      "[CV 5/5] END base_score=0.5, booster=dart, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=5, n_estimators=1500;, score=(train=1.000, test=0.896) total time= 8.0min\n",
      "[CV 2/5] END base_score=0.5, booster=dart, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=1100;, score=(train=0.999, test=0.846) total time= 3.4min\n",
      "[22:57:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50;, score=(train=0.823, test=0.833) total time=   0.0s\n",
      "[22:57:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50;, score=(train=0.823, test=0.830) total time=   0.0s\n",
      "[22:57:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50;, score=(train=0.825, test=0.825) total time=   0.0s\n",
      "[22:57:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50;, score=(train=0.826, test=0.822) total time=   0.0s\n",
      "[22:57:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50;, score=(train=0.827, test=0.813) total time=   0.0s\n",
      "[22:57:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1100;, score=(train=0.821, test=0.834) total time=   0.9s\n",
      "[22:57:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1100;, score=(train=0.822, test=0.828) total time=   0.9s\n",
      "[22:57:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1100;, score=(train=0.823, test=0.820) total time=   0.8s\n",
      "[22:57:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1100;, score=(train=0.824, test=0.820) total time=   0.9s\n",
      "[22:57:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1100;, score=(train=0.825, test=0.813) total time=   0.9s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=1500;, score=(train=0.975, test=0.867) total time=   5.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=1500;, score=(train=0.976, test=0.869) total time=   5.2s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=1500;, score=(train=0.974, test=0.870) total time=   5.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=1500;, score=(train=0.974, test=0.880) total time=   5.2s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=1500;, score=(train=0.975, test=0.859) total time=   5.1s\n",
      "[CV 1/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.1, learning_rate=0.2, max_depth=12, min_child_weight=3, n_estimators=1500;, score=(train=1.000, test=0.903) total time=  11.4s\n",
      "[CV 2/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.1, learning_rate=0.2, max_depth=12, min_child_weight=3, n_estimators=1500;, score=(train=1.000, test=0.910) total time=  11.4s\n",
      "[CV 4/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.1, learning_rate=0.2, max_depth=12, min_child_weight=3, n_estimators=1500;, score=(train=1.000, test=0.909) total time=  10.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:32:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=7, min_child_weight=2, n_estimators=200;, score=(train=0.823, test=0.820) total time=   0.1s\n",
      "[CV 2/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=7, min_child_weight=5, n_estimators=100;, score=(train=0.942, test=0.880) total time=   0.3s\n",
      "[22:32:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=4, n_estimators=1100;, score=(train=0.821, test=0.833) total time=   0.6s\n",
      "[22:32:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=4, n_estimators=1100;, score=(train=0.826, test=0.814) total time=   0.7s\n",
      "[CV 4/5] END base_score=0.25, booster=dart, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=12, min_child_weight=2, n_estimators=200;, score=(train=1.000, test=0.913) total time=  11.7s\n",
      "[CV 5/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=50;, score=(train=0.993, test=0.907) total time=   0.3s\n",
      "[22:32:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=5, n_estimators=500;, score=(train=0.824, test=0.821) total time=   0.3s\n",
      "[CV 1/5] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=4, n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=4, n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=4, n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=4, n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=4, n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END base_score=1, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=1100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END base_score=1, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=1100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=1100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=1100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=1100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END base_score=0.75, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=2, n_estimators=50;, score=(train=0.979, test=0.902) total time=   0.9s\n",
      "[CV 5/5] END base_score=0.75, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=2, n_estimators=50;, score=(train=0.978, test=0.898) total time=   1.0s\n",
      "[22:32:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7999999999999999, colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.821, test=0.833) total time=   0.3s\n",
      "[CV 2/5] END base_score=0.25, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0.2, learning_rate=0.2, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=0.969, test=0.915) total time=   1.7s\n",
      "[CV 3/5] END base_score=0.25, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0.2, learning_rate=0.2, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=0.968, test=0.917) total time=   1.8s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=5, n_estimators=100;, score=(train=0.961, test=0.870) total time=   0.4s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=5, n_estimators=100;, score=(train=0.960, test=0.881) total time=   0.4s\n",
      "[22:32:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.823, test=0.820) total time=   0.1s\n",
      "[22:32:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.825, test=0.813) total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.2, learning_rate=0.3, max_depth=2, min_child_weight=2, n_estimators=500;, score=(train=0.939, test=0.886) total time=   0.7s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.2, learning_rate=0.3, max_depth=2, min_child_weight=2, n_estimators=500;, score=(train=0.940, test=0.876) total time=   0.7s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=0.0, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=1500;, score=(train=0.999, test=0.909) total time=   3.4s\n",
      "[22:32:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7999999999999999, colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=2, n_estimators=500;, score=(train=0.822, test=0.834) total time=   0.3s\n",
      "[22:32:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7999999999999999, colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=2, n_estimators=500;, score=(train=0.824, test=0.821) total time=   0.3s\n",
      "[CV 2/5] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=2, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=2, n_estimators=50;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[22:32:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=0.821, test=0.834) total time=   0.7s\n",
      "[22:32:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=1100;, score=(train=0.825, test=0.813) total time=   0.7s\n",
      "[CV 3/5] END base_score=0.75, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=1, n_estimators=50;, score=(train=0.952, test=0.908) total time=   0.7s\n",
      "[22:32:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=2, n_estimators=1100;, score=(train=0.821, test=0.833) total time=   0.8s\n",
      "[22:32:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=2, n_estimators=1100;, score=(train=0.825, test=0.821) total time=   0.7s\n",
      "[CV 4/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=100;, score=(train=0.999, test=0.909) total time=   0.7s\n",
      "[CV 2/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=4, n_estimators=1500;, score=(train=0.979, test=0.864) total time=   6.1s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=2, min_child_weight=5, n_estimators=100;, score=(train=0.909, test=0.897) total time=   0.1s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=2, min_child_weight=5, n_estimators=100;, score=(train=0.909, test=0.893) total time=   0.2s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=2, min_child_weight=5, n_estimators=100;, score=(train=0.912, test=0.884) total time=   0.2s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=5, n_estimators=50;, score=(train=0.922, test=0.906) total time=   0.1s\n",
      "[CV 1/5] END base_score=0.75, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.3, gamma=0.2, learning_rate=0.2, max_depth=12, min_child_weight=5, n_estimators=500;, score=(train=0.989, test=0.856) total time= 1.2min\n",
      "[CV 2/5] END base_score=0.5, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.2, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.901) total time=  40.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.2, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.899) total time=  40.1s\n",
      "[CV 4/5] END base_score=0.25, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=1100;, score=(train=1.000, test=0.913) total time= 3.2min\n",
      "[CV 2/5] END base_score=0.5, booster=dart, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=5, n_estimators=1500;, score=(train=1.000, test=0.900) total time= 8.0min\n",
      "[CV 2/5] END base_score=0.25, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=1100;, score=(train=0.999, test=0.904) total time= 4.3min\n",
      "[CV 5/5] END base_score=0.25, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=1100;, score=(train=0.999, test=0.900) total time= 4.1min\n",
      "[CV 4/5] END base_score=0.5, booster=dart, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=1100;, score=(train=0.999, test=0.867) total time= 3.6min\n",
      "[CV 5/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.1, learning_rate=0.2, max_depth=12, min_child_weight=3, n_estimators=1500;, score=(train=1.000, test=0.903) total time=  10.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:32:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=7, min_child_weight=2, n_estimators=200;, score=(train=0.825, test=0.821) total time=   0.1s\n",
      "[CV 3/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=7, min_child_weight=5, n_estimators=100;, score=(train=0.943, test=0.876) total time=   0.3s\n",
      "[CV 5/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=7, min_child_weight=5, n_estimators=100;, score=(train=0.944, test=0.865) total time=   0.4s\n",
      "[22:32:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=4, n_estimators=1100;, score=(train=0.825, test=0.821) total time=   0.7s\n",
      "[CV 3/5] END base_score=0.25, booster=dart, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=12, min_child_weight=2, n_estimators=200;, score=(train=1.000, test=0.914) total time=  11.5s\n",
      "[22:32:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=50;, score=(train=0.761, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=50;, score=(train=0.992, test=0.912) total time=   0.3s\n",
      "[CV 3/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=50;, score=(train=0.995, test=0.917) total time=   0.3s\n",
      "[CV 1/5] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[22:32:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=5, n_estimators=500;, score=(train=0.823, test=0.829) total time=   0.3s\n",
      "[22:32:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.4, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=5, n_estimators=500;, score=(train=0.826, test=0.815) total time=   0.3s\n",
      "[CV 2/5] END base_score=0.75, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=2, n_estimators=50;, score=(train=0.979, test=0.908) total time=   1.0s\n",
      "[22:32:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7999999999999999, colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.822, test=0.828) total time=   0.3s\n",
      "[22:32:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7999999999999999, colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.823, test=0.820) total time=   0.4s\n",
      "[22:32:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7999999999999999, colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.825, test=0.821) total time=   0.4s\n",
      "[22:32:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7999999999999999, colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.826, test=0.814) total time=   0.3s\n",
      "[CV 4/5] END base_score=0.25, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0.2, learning_rate=0.2, max_depth=5, min_child_weight=2, n_estimators=100;, score=(train=0.970, test=0.922) total time=   1.8s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=200;, score=(train=0.922, test=0.910) total time=   0.4s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=200;, score=(train=0.923, test=0.911) total time=   0.4s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=200;, score=(train=0.923, test=0.907) total time=   0.4s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=200;, score=(train=0.922, test=0.913) total time=   0.4s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=5, n_estimators=100;, score=(train=0.961, test=0.870) total time=   0.4s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=5, n_estimators=100;, score=(train=0.962, test=0.862) total time=   0.4s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.2, learning_rate=0.3, max_depth=2, min_child_weight=2, n_estimators=500;, score=(train=0.936, test=0.886) total time=   0.7s\n",
      "[CV 1/5] END base_score=1, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END base_score=1, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END base_score=1, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END base_score=1, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[22:32:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=7, min_child_weight=3, n_estimators=100;, score=(train=0.822, test=0.835) total time=   0.1s\n",
      "[22:32:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=7, min_child_weight=3, n_estimators=100;, score=(train=0.823, test=0.829) total time=   0.1s\n",
      "[22:32:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=7, min_child_weight=3, n_estimators=100;, score=(train=0.824, test=0.824) total time=   0.1s\n",
      "[22:32:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=7, min_child_weight=3, n_estimators=100;, score=(train=0.826, test=0.822) total time=   0.1s\n",
      "[22:32:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=7, min_child_weight=3, n_estimators=100;, score=(train=0.827, test=0.812) total time=   0.1s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=0.0, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=1500;, score=(train=1.000, test=0.903) total time=   3.4s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=0.0, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=1500;, score=(train=1.000, test=0.904) total time=   3.4s\n",
      "[22:32:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=2, n_estimators=1100;, score=(train=0.823, test=0.820) total time=   0.7s\n",
      "[CV 3/5] END base_score=1, booster=dart, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END base_score=1, booster=dart, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=1500;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=100;, score=(train=0.999, test=0.905) total time=   0.7s\n",
      "[22:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.2, learning_rate=0.3, max_depth=12, min_child_weight=5, n_estimators=100;, score=(train=0.821, test=0.834) total time=   0.1s\n",
      "[22:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.2, learning_rate=0.3, max_depth=12, min_child_weight=5, n_estimators=100;, score=(train=0.822, test=0.828) total time=   0.1s\n",
      "[22:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.2, learning_rate=0.3, max_depth=12, min_child_weight=5, n_estimators=100;, score=(train=0.823, test=0.820) total time=   0.1s\n",
      "[22:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.2, learning_rate=0.3, max_depth=12, min_child_weight=5, n_estimators=100;, score=(train=0.825, test=0.821) total time=   0.1s\n",
      "[22:32:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.2, learning_rate=0.3, max_depth=12, min_child_weight=5, n_estimators=100;, score=(train=0.826, test=0.813) total time=   0.1s\n",
      "[CV 1/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=4, n_estimators=1500;, score=(train=0.979, test=0.863) total time=   6.1s\n",
      "[CV 5/5] END base_score=0.75, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.3, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=4, n_estimators=1500;, score=(train=0.979, test=0.856) total time=   7.8s\n",
      "[CV 4/5] END base_score=0.75, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.3, gamma=0.2, learning_rate=0.2, max_depth=12, min_child_weight=5, n_estimators=500;, score=(train=0.990, test=0.870) total time= 1.2min\n",
      "[CV 3/5] END base_score=0.5, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.4, gamma=0.2, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.907) total time=  39.3s\n",
      "[CV 1/5] END base_score=0.25, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=1100;, score=(train=1.000, test=0.906) total time= 3.2min\n",
      "[CV 5/5] END base_score=0.25, booster=dart, colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=2, n_estimators=1100;, score=(train=1.000, test=0.907) total time= 3.4min\n",
      "[CV 4/5] END base_score=0.5, booster=dart, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=5, n_estimators=1500;, score=(train=1.000, test=0.905) total time= 8.0min\n",
      "[CV 3/5] END base_score=0.25, booster=dart, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=1100;, score=(train=0.999, test=0.904) total time= 4.1min\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=2, n_estimators=50;, score=(train=0.920, test=0.905) total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=2, n_estimators=50;, score=(train=0.921, test=0.904) total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=2, n_estimators=50;, score=(train=0.923, test=0.904) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=2, n_estimators=50;, score=(train=0.921, test=0.907) total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=2, n_estimators=50;, score=(train=0.922, test=0.896) total time=   0.1s\n",
      "[22:53:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=1100;, score=(train=0.821, test=0.834) total time=   0.8s\n",
      "[22:53:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=1100;, score=(train=0.822, test=0.828) total time=   0.8s\n",
      "[22:53:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=1100;, score=(train=0.823, test=0.820) total time=   0.8s\n",
      "[22:53:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=1100;, score=(train=0.825, test=0.820) total time=   0.8s\n",
      "[22:53:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, gamma=0.4, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=1100;, score=(train=0.826, test=0.814) total time=   0.8s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=1100;, score=(train=0.999, test=0.845) total time= 3.5min\n",
      "[CV 5/5] END base_score=0.5, booster=dart, colsample_bylevel=0.6, colsample_bytree=0.3, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=1100;, score=(train=0.999, test=0.840) total time= 2.5min\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "classifier = xgboost.XGBClassifier()\n",
    "random_cv = RandomizedSearchCV(estimator=classifier, param_distributions=hyperparameter_grid, cv=5,n_iter=50, \n",
    "                               scoring = 'roc_auc',n_jobs = 4,\n",
    "                               verbose = 5, return_train_score = True, random_state=42)\n",
    "random_cv.fit(Xtr_standardized, ytr_standardized)\n",
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bh/y2kw037n4lxc00q7zyvbyn080000gn/T/ipykernel_41377/3107019422.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'random_cv' is not defined"
     ]
    }
   ],
   "source": [
    "random_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.75, booster='dart', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.5,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=5, max_leaves=0, min_child_weight=4, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=xgboost.XGBClassifier(random_cv.best_estimator_)\n",
    "\n",
    "model.fit(Xtr_standardized, ytr_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model: you must use the .json format for xgboost models!\n",
    "model_savepath = 'model.json'\n",
    "model.save_model(model_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training auc =  0.9433362596673114\r\n",
      "test label confidences saved in yts_hat_xgboost.csv\r\n"
     ]
    }
   ],
   "source": [
    "# generate kaggle submission file using the validation script\n",
    "!python {\"validation.py \" + model_savepath + \" --Xts_path \" + Xts_savepath + \" --Xtr_path \" + Xtr_savepath + \" --yts_hat_path \" + yts_hat_savepath }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
